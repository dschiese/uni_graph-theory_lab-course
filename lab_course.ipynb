{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfdca0e",
   "metadata": {},
   "source": [
    "# Notes jupyternotebook\n",
    "Only for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"schneider50k_clean.tsv\",sep=\"\\t\")\n",
    "\n",
    "# original_rxn: the mapped reaction SMILES (to be transformed for kernels)\n",
    "# rxn_class: the classification class of the reaction (to be learned)\n",
    "\n",
    "# Remove source\n",
    "df.drop(columns=[\"source\"], inplace=True)\n",
    "\n",
    "# Count how many different and distinct rxn_class exist and how many reactions per class\n",
    "print(\"Number of different classes:\", len(df[\"rxn_class\"].unique()))\n",
    "print(\"Number of reactions per class:\")\n",
    "print(df[\"rxn_class\"].value_counts())\n",
    "\n",
    "# Pick 5 random, distinct classes and save them to a new file\n",
    "random_classes = df[\"rxn_class\"].drop_duplicates().sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [O:22]=[C:14]([NH:13][CH2:12][CH2:11][NH:10][c:3]1[n:2][s:1][c:5]2[cH:6][cH:7][cH:8][cH:9][c:4]21)[c:15]1[cH:16][c:17](Cl)[cH:18][cH:19][n:20]1.[CH2:27]1[CH2:26][O:25][CH2:24][CH2:23][NH:28]1>>[O:22]=[C:14]([NH:13][CH2:12][CH2:11][NH:10][c:3]1[n:2][s:1][c:5]2[cH:6][cH:7][cH:8][cH:9][c:4]21)[c:15]1[cH:16][c:17]([N:28]2[CH2:27][CH2:26][O:25][CH2:24][CH2:23]2)[cH:18][cH:19][n:20]1\n",
    "\n",
    "from scripts import plot_and_print_its_graphs\n",
    "from networkx.algorithms import all_pairs_shortest_path, floyd_warshall\n",
    "from synkit.IO import rsmi_to_graph\n",
    "\n",
    "#plot_and_print_its_graphs(df.iloc[46][\"original_rxn\"])\n",
    "\n",
    "educt, product = rsmi_to_graph(df.iloc[46][\"original_rxn\"])\n",
    "\n",
    "# Transform educt to undirected graph\n",
    "educt = educt.to_undirected()\n",
    "\n",
    "paths = dict(floyd_warshall(educt))\n",
    "\n",
    "# Print all shortest paths\n",
    "for source_node, target_dict in paths.items():\n",
    "    for target_node, path in target_dict.items():\n",
    "        print(f\"Shortest path from {source_node} to {target_node}: {path}\")\n",
    "\n",
    "# There exist equivalent paths but inversed, needs to be cleaned up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize by rxn_class and count\n",
    "class_counts = df['rxn_class'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc52220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create varied sets containing 3-5 different classes and each 20-200 reactions\n",
    "import random\n",
    "\n",
    "def create_varied_set(classes:int, reactions_per_class:int) -> pd.DataFrame:\n",
    "    selected_classes = random.sample(list(class_counts.index), classes)\n",
    "    varied_set = pd.DataFrame()\n",
    "\n",
    "    for cls in selected_classes:\n",
    "        if not reactions_per_class:\n",
    "            reactions_per_class = random.randint(20, 200)\n",
    "        class_subset = df[df['rxn_class'] == cls].sample(n=reactions_per_class, random_state=42)\n",
    "        varied_set = pd.concat([varied_set, class_subset])\n",
    "\n",
    "    return varied_set.reset_index(drop=True)\n",
    "\n",
    "print(create_varied_set(4, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2823f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import plot_and_print_its_graphs\n",
    "from phi_transformation import phi_vertex\n",
    "\n",
    "for i in range(5):\n",
    "  try:\n",
    "    reaction = df.iloc[i][\"clean_rxn\"]\n",
    "    plot_and_print_its_graphs(reaction)\n",
    "  except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c051078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import plot_and_print_its_graphs\n",
    "from phi_transformation import phi_vertex\n",
    "from synkit.IO import rsmi_to_graph\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "  try:\n",
    "    reaction = df.iloc[i][\"clean_rxn\"]\n",
    "    educt_graph, product_graph = rsmi_to_graph(reaction)\n",
    "    print(f\"Educt graph: {phi_vertex(educt_graph)}\")\n",
    "    print(f\"Product graph: {phi_vertex(product_graph)}\")\n",
    "  except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d16a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi_transformation import phi_shortest_path\n",
    "\n",
    "t = phi_shortest_path(\"[CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10][CH2:9][N:8](Cc2ccccc2)[CH2:13][CH2:12]1>>[CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10][CH2:9][NH:8][CH2:13][CH2:12]1\")\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb36ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import all_pairs_shortest_path\n",
    "from synkit.IO import rsmi_to_graph\n",
    "\n",
    "graph, _ = rsmi_to_graph(\"[CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10][CH2:9][N:8](Cc2ccccc2)[CH2:13][CH2:12]1>>[CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10][CH2:9][NH:8][CH2:13][CH2:12]1\")\n",
    "\n",
    "for n, d in graph.nodes(data=True):\n",
    "  # Store mapping of node to label\n",
    "  node_to_label = {n: d[\"element\"] for n, d in graph.nodes(data=True)}\n",
    "  \n",
    "print(node_to_label)\n",
    "\n",
    "paths = dict(all_pairs_shortest_path(graph))\n",
    "\n",
    "# For each path, convert to string representation\n",
    "for source, target_dict in paths.items():\n",
    "  for target, path in target_dict.items():\n",
    "    # Print path\n",
    "    print(f\"Path from {source} to {target}: {' -> '.join(map(str, path))}\")\n",
    "    # Convert the path to label concatenation using node_to_label\n",
    "    label_path = ''.join(node_to_label[n] for n in path)\n",
    "    print(f\"Label path: {label_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9cedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read schneider_50k_clean.tsv, extract the clean_rxn column and write every reaction to a separate line in reactions.txt\n",
    "with open(\"reactions.txt\", \"w\") as f:\n",
    "    for i in range(len(df)):\n",
    "        reaction = df.iloc[i][\"clean_rxn\"]\n",
    "        f.write(reaction + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files from data/*\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read schneider50k\n",
    "with open(\"schneider50k_clean.tsv\", \"r\") as f:\n",
    "    schneider50k = pd.read_csv(f, sep=\"\\t\")\n",
    "\n",
    "with open(\"data/pre-computed-feature_sets_part_1.xlsx\", \"rb\") as f:\n",
    "    part1 = pd.read_excel(f)\n",
    "    # Print all rows\n",
    "    print(part1)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for filename in glob.glob(\"data/*.xlsx\"):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pd.read_excel(f)\n",
    "        data = pd.concat([data, data], ignore_index=True)\n",
    "\n",
    "# Append schneider50k[rxn_class] to data\n",
    "data = pd.concat([data, schneider50k[['rxn_class']]], axis=1)\n",
    "\n",
    "# Validate all columns exist\n",
    "\n",
    "required_columns = [\n",
    "    \"educt_phi_vertex_dict\",\n",
    "    \"product_phi_vertex_dict\",\n",
    "    \"symmetric_difference_vertex_dict\",\n",
    "    \"educt_phi_edge\",\n",
    "    \"product_phi_edge\",\n",
    "    \"symmetric_difference_edge\",\n",
    "    \"educt_phi_shortest_path\",\n",
    "    \"product_phi_shortest_path\",\n",
    "    \"symmetric_difference_shortest_path\",\n",
    "    \"rxn_class\"\n",
    "]\n",
    "with open(\"data/combined_data.xlsx\", \"wb\") as f:\n",
    "  data.to_excel(f, index=False)\n",
    "\n",
    "# Validaate 49999 < rows < 50001\n",
    "assert len(data) > 49999 and len(data) < 50001, f\"Data has {len(data)} rows, expected ~50000\"\n",
    "print(\"Data validation passed: correct number of rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data/combined_data.xlsx and print the columns\n",
    "import pandas as pd\n",
    "df = pd.read_excel(\"data/combined_data.xlsx\")\n",
    "print(\"Columns in combined_data.xlsx:\", df.columns.tolist())\n",
    "\n",
    "# DRF Nodes = Symm. Diff of Nodes\n",
    "# DRF Edges = Symm. Diff of Edges\n",
    "# DRF Shortest Paths = Symm. Diff of Shortest Paths\n",
    "\n",
    "# Bei ITS existiert nur ein \n",
    "# ITS Nodes = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
